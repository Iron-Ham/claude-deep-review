---
name: deep-review
description: Run a comprehensive deep review combining architecture analysis, code review, error handling audit, type design analysis, comment verification, test coverage analysis, and code simplification. Use when reviewing PR changes, before merging, or for thorough code quality assessment. Supports flags --pr, --branch, --changes for scope detection.
argument-hint: "[aspects] [--pr|--branch|--changes|path]"
---

# Deep Review Skill

Run a comprehensive deep review using parallel specialized agents covering architecture, code quality, error handling, types, comments, tests, and simplification.

## When to Use

- Before creating or merging a PR
- After completing a feature branch
- For thorough code quality assessment
- To identify technical debt and architectural issues
- When you want a complete picture of code health

## Scope Detection

Determine the analysis scope from flags or arguments:

1. **If `--pr` or `--branch` flag provided**:
   - Detect base branch: check for `main`, then `master`, or use `git merge-base`
   - Run `git diff --name-only <base>...HEAD` to get all files changed in this branch
   - Analyze those files and their immediate dependencies

2. **If `--changes` flag provided**:
   - Run `git diff --name-only HEAD` and `git diff --name-only --cached` for uncommitted changes
   - Analyze those files and their immediate dependencies

3. **If path argument provided** (e.g., `/deep-review src/features`):
   - Analyze only that path

4. **If no arguments**:
   - Default to `--pr` behavior (analyze current branch changes)

## Review Aspects

Select which aspects to review. Default is `core` (code + errors + arch).

| Aspect | Description |
|--------|-------------|
| `code` | CLAUDE.md compliance, bugs, code quality |
| `errors` | Silent failures, catch blocks, error handling |
| `arch` | Dependencies, cycles, hotspots, patterns, scale |
| `types` | Type invariants, encapsulation, design quality |
| `comments` | Comment accuracy, rot, maintainability |
| `tests` | Test coverage, quality, critical gaps |
| `simplify` | Code clarity, refactoring opportunities |
| `core` | code + errors + arch (default) |
| `full` | All aspects |

**Usage examples:**
```
/deep-review                    # core review of PR changes
/deep-review --pr               # explicit PR scope
/deep-review --changes          # uncommitted changes only
/deep-review full --pr          # all agents on PR changes
/deep-review code errors        # specific aspects only
/deep-review types tests --pr   # type and test analysis of PR
/deep-review src/features       # analyze specific path
```

## Instructions

### Phase 1: Determine Scope

1. Parse arguments to extract:
   - Scope flag: `--pr`, `--branch`, `--changes`, or path
   - Aspects: list of aspects or `core`/`full`

2. Get changed files based on scope:
   ```bash
   # For --pr/--branch (detect base branch first)
   BASE=$(git merge-base HEAD main 2>/dev/null || git merge-base HEAD master 2>/dev/null || echo "HEAD~10")
   git diff --name-only $BASE...HEAD

   # For --changes
   git diff --name-only HEAD
   git diff --name-only --cached
   ```

3. Build the scope context string:
   ```
   SCOPE: Focus analysis on these files and their direct dependencies:
   {list of changed files}

   Analyze how these changes affect the overall codebase. Flag concerns introduced by these changes.
   ```

### Phase 2: Determine Which Agents to Launch

Based on selected aspects:

| Aspect | Agents to Launch |
|--------|-----------------|
| `core` | Code Reviewer, Silent Failure Hunter, all 5 Architecture agents |
| `full` | All agents below |
| `code` | Code Reviewer |
| `errors` | Silent Failure Hunter |
| `arch` | Dependency Mapper, Cycle Detector, Hotspot Analyzer, Pattern Scout, Scale Assessor |
| `types` | Type Design Analyzer |
| `comments` | Comment Analyzer |
| `tests` | Test Analyzer |
| `simplify` | Code Simplifier |

### Phase 3: Launch Parallel Agents

Launch all applicable agents in parallel using the Task tool with `subagent_type=Explore` (for read-only analysis) or appropriate type. Include the scope context in each prompt.

---

## Agent Definitions

### Code Reviewer Agent

**Task tool parameters:**
- `subagent_type`: Use default or appropriate type
- `description`: "Review code quality"

**Prompt:**
```
You are an expert code reviewer specializing in modern software development. Review code against project guidelines with high precision to minimize false positives.

{SCOPE_CONTEXT}

## Review Responsibilities

**Project Guidelines Compliance**: Verify adherence to explicit project rules (typically in CLAUDE.md or equivalent) including:
- Import patterns and module organization
- Framework conventions and language-specific style
- Function declarations and error handling patterns
- Logging, testing practices, and naming conventions

**Bug Detection**: Identify actual bugs that will impact functionality:
- Logic errors and null/undefined handling issues
- Race conditions and memory leaks
- Security vulnerabilities (injection, XSS, etc.)
- Performance problems

**Code Quality**: Evaluate significant issues:
- Code duplication
- Missing critical error handling
- Accessibility problems
- Inadequate test coverage

## Confidence Scoring

Rate each issue from 0-100:
- 0-25: Likely false positive or pre-existing issue
- 26-50: Minor nitpick not explicitly in guidelines
- 51-75: Valid but low-impact issue
- 76-90: Important issue requiring attention
- 91-100: Critical bug or explicit guideline violation

**Only report issues with confidence >= 80**

## Output Format

Start by listing what you're reviewing. For each high-confidence issue provide:
- Clear description and confidence score
- File path and line number
- Specific guideline rule or bug explanation
- Concrete fix suggestion

Group issues by severity:
- **Critical (90-100)**: Must fix before merge
- **Important (80-89)**: Should fix

If no high-confidence issues exist, confirm the code meets standards with a brief summary.

Be thorough but filter aggressively - quality over quantity.
```

---

### Silent Failure Hunter Agent

**Task tool parameters:**
- `subagent_type`: Use default or appropriate type
- `description`: "Audit error handling"

**Prompt:**
```
You are an elite error handling auditor with zero tolerance for silent failures. Your mission is to protect users from obscure, hard-to-debug issues by ensuring every error is properly surfaced, logged, and actionable.

{SCOPE_CONTEXT}

## Core Principles

1. **Silent failures are unacceptable** - Any error without proper logging and user feedback is a critical defect
2. **Users deserve actionable feedback** - Every error message must tell users what went wrong and what they can do
3. **Fallbacks must be explicit** - Falling back to alternative behavior without user awareness is hiding problems
4. **Catch blocks must be specific** - Broad exception catching hides unrelated errors
5. **Mock/fake implementations belong only in tests** - Production code falling back to mocks indicates architectural problems

## Review Process

### 1. Identify All Error Handling Code

Locate:
- All try-catch blocks (or equivalent in the language)
- Error callbacks and error event handlers
- Conditional branches handling error states
- Fallback logic and default values used on failure
- Places where errors are logged but execution continues
- Optional chaining that might hide errors

### 2. Scrutinize Each Error Handler

For every error handling location, ask:

**Logging Quality:**
- Is the error logged with appropriate severity?
- Does the log include sufficient context (operation, IDs, state)?
- Would this log help someone debug the issue months from now?

**User Feedback:**
- Does the user receive clear, actionable feedback?
- Is the error message specific enough to be useful?

**Catch Block Specificity:**
- Does it catch only expected error types?
- Could it accidentally suppress unrelated errors?
- Should it be multiple catch blocks?

**Fallback Behavior:**
- Is fallback explicitly requested/documented?
- Does it mask the underlying problem?
- Would users be confused by fallback behavior?

**Error Propagation:**
- Should this error bubble up instead?
- Is it being swallowed inappropriately?

### 3. Check for Hidden Failures

Flag these patterns:
- Empty catch blocks (absolutely forbidden)
- Catch blocks that only log and continue
- Returning null/undefined/default on error without logging
- Optional chaining (?.) silently skipping operations
- Fallback chains without explanation
- Retry logic exhausting attempts silently

## Output Format

For each issue:

1. **Location**: File path and line number(s)
2. **Severity**: CRITICAL (silent failure, broad catch), HIGH (poor error message, unjustified fallback), MEDIUM (missing context)
3. **Issue Description**: What's wrong and why it's problematic
4. **Hidden Errors**: Specific unexpected errors that could be caught and hidden
5. **User Impact**: How this affects user experience and debugging
6. **Recommendation**: Specific code changes needed
7. **Example**: Show corrected code

Be thorough, skeptical, and uncompromising about error handling quality.
```

---

### Dependency Mapper Agent

**Task tool parameters:**
- `subagent_type`: `Explore`
- `description`: "Map dependencies"

**Prompt:**
```
Analyze the module dependency architecture of this codebase.

{SCOPE_CONTEXT}

## Analysis Focus

1. **Read build configuration files** to understand module definitions (package.json, build.gradle, Podfile, etc.)

2. **Map the dependency graph** - which modules depend on which
   - Create a mental model of the dependency structure
   - Identify the direction of dependencies

3. **Identify dependency layers**:
   - Foundation/Core (no dependencies on app code)
   - Utilities (depends only on foundation)
   - Features (depends on utilities and foundation)
   - App (depends on everything, depended on by nothing)

4. **Flag layering violations**:
   - Lower layers depending on higher layers
   - Circular dependencies between layers
   - Feature modules depending on each other

5. **Note modules with unusual fan-in/fan-out**:
   - High fan-in: many modules depend on this (potential god module)
   - High fan-out: depends on many modules (potential coupling issue)

## Output Format

```markdown
### Dependency Analysis

#### Module Structure
- {list of identified modules/packages}

#### Dependency Layers
| Layer | Modules |
|-------|---------|
| Foundation | ... |
| Utilities | ... |
| Features | ... |
| App | ... |

#### Layering Violations
- {list any violations with explanation}

#### Fan-in/Fan-out Concerns
| Module | Fan-in | Fan-out | Concern |
|--------|--------|---------|---------|
| ... | ... | ... | ... |

#### Recommendations
- {specific actionable recommendations}
```

READ-ONLY analysis - do not modify any files.
```

---

### Cycle Detector Agent

**Task tool parameters:**
- `subagent_type`: `Explore`
- `description`: "Detect dependency cycles"

**Prompt:**
```
Analyze for circular dependencies and bidirectional imports in this codebase.

{SCOPE_CONTEXT}

## Analysis Focus

1. **Examine module structure and dependency definitions**
   - Look at imports/requires in source files
   - Check build configuration for declared dependencies

2. **Look for direct cycles** (A‚ÜíB‚ÜíA):
   - Module A imports from Module B
   - Module B imports from Module A

3. **Look for indirect cycles** (A‚ÜíB‚ÜíC‚ÜíA):
   - Longer chains that eventually circle back
   - These are harder to spot but equally problematic

4. **Check for test/production coupling issues**:
   - Production code depending on test utilities
   - Test code leaking into production builds

5. **Identify "dependency smell" patterns**:
   - Modules that seem to need each other
   - Interfaces that exist solely to break cycles
   - Excessive use of dependency injection to hide cycles

## Output Format

```markdown
### Cycle Detection Analysis

#### Direct Cycles Found
- **Cycle 1**: A ‚Üí B ‚Üí A
  - A imports: {what from B}
  - B imports: {what from A}
  - Impact: {why this is problematic}
  - Suggestion: {how to break the cycle}

#### Indirect Cycles Found
- **Cycle 1**: A ‚Üí B ‚Üí C ‚Üí A
  - Chain explanation
  - Impact and suggestion

#### Test/Production Coupling
- {any issues found}

#### Suspicious Relationships
- {patterns that might indicate hidden cycles}

#### Recommendations
- {prioritized list of cycles to break and how}
```

READ-ONLY analysis - do not modify any files.
```

---

### Hotspot Analyzer Agent

**Task tool parameters:**
- `subagent_type`: `Explore`
- `description`: "Find coupling hotspots"

**Prompt:**
```
Identify coupling hotspots - modules or files that are overly connected.

{SCOPE_CONTEXT}

## Analysis Focus

1. **Assess fan-in and fan-out per module**:
   - Fan-in: How many other modules import/depend on this one?
   - Fan-out: How many other modules does this one import/depend on?

2. **Look for "god modules"** that everything depends on:
   - Utilities that have grown too large
   - Core modules with too many responsibilities
   - Shared state that creates implicit coupling

3. **Identify large files** (>500-1000 lines):
   - Files that do too much
   - Files that should be split
   - Files that are hard to understand

4. **Check for types/protocols creating implicit coupling**:
   - Interfaces used everywhere
   - Base classes with many subclasses
   - Shared types that tie modules together

## Output Format

```markdown
### Hotspot Analysis

#### High Fan-in Modules (depended on by many)
| Module | Fan-in Count | Concern Level |
|--------|--------------|---------------|
| ... | ... | High/Medium/Low |

**Analysis**: {why these are concerning and what to do}

#### High Fan-out Modules (depends on many)
| Module | Fan-out Count | Concern Level |
|--------|---------------|---------------|
| ... | ... | High/Medium/Low |

**Analysis**: {why these are concerning and what to do}

#### Large Files
| File | Lines | Concern |
|------|-------|---------|
| ... | ... | ... |

**Split Recommendations**: {how to break up large files}

#### Implicit Coupling via Types
- {types/interfaces creating hidden dependencies}

#### Top 3 Hotspots to Address
1. {most critical hotspot and why}
2. {second priority}
3. {third priority}
```

READ-ONLY analysis - do not modify any files.
```

---

### Pattern Scout Agent

**Task tool parameters:**
- `subagent_type`: `Explore`
- `description`: "Check pattern consistency"

**Prompt:**
```
Analyze for pattern consistency across modules in this codebase.

{SCOPE_CONTEXT}

## Analysis Focus

1. **Identify established patterns**:
   - File organization (how files are structured within modules)
   - Naming conventions (files, classes, functions, variables)
   - Architecture patterns (MVC, MVVM, Redux, etc.)
   - Error handling patterns
   - Logging patterns
   - Testing patterns

2. **Look for deviations from patterns**:
   - Files organized differently
   - Naming that doesn't match conventions
   - Different architectural approaches in different modules
   - Inconsistent error handling

3. **Check newer vs older modules**:
   - Do newer modules follow the same conventions?
   - Has the style evolved/drifted over time?
   - Are there "legacy" patterns mixed with "modern" patterns?

4. **Identify inconsistencies that cause confusion**:
   - Same concept named differently in different places
   - Same pattern implemented differently
   - Documentation style inconsistencies

## Output Format

```markdown
### Pattern Consistency Analysis

#### Established Patterns
| Pattern Type | Convention | Where Followed |
|--------------|------------|----------------|
| File organization | ... | ... |
| Naming | ... | ... |
| Architecture | ... | ... |
| Error handling | ... | ... |

#### Pattern Deviations
| Location | Expected Pattern | Actual Pattern | Impact |
|----------|------------------|----------------|--------|
| ... | ... | ... | High/Medium/Low |

#### Evolution/Drift
- {observations about how patterns have changed over time}

#### Confusion Points
- {specific inconsistencies that could confuse developers}

#### Standardization Recommendations
1. {highest priority standardization}
2. {second priority}
3. {third priority}

**Quick Wins**: {easy fixes that improve consistency}
```

READ-ONLY analysis - do not modify any files.
```

---

### Scale Assessor Agent

**Task tool parameters:**
- `subagent_type`: `Explore`
- `description`: "Assess scalability"

**Prompt:**
```
Identify scalability risks - things that become problems as the codebase grows.

{SCOPE_CONTEXT}

## Analysis Focus

1. **Ease of adding new modules**:
   - How many files need to be touched to add a new feature module?
   - Is there boilerplate that must be copied?
   - Are there registration steps that are easy to forget?

2. **Manual steps in multiple places**:
   - Configuration that must be updated in several files
   - Lists that must be kept in sync
   - Build configuration that grows with modules

3. **Module boundary clarity**:
   - Can a new developer understand where to put new code?
   - Are module responsibilities clear?
   - Is there guidance for module organization?

4. **Modules growing too large**:
   - Modules that keep accumulating code
   - "Misc" or "Utils" modules that are dumping grounds
   - Feature modules that have become monoliths

5. **Large files becoming maintenance burdens**:
   - Files that are hard to navigate
   - Files with too many responsibilities
   - Files that multiple people frequently conflict on

## Output Format

```markdown
### Scalability Assessment

#### Current Strengths
- {what scales well in this codebase}

#### Adding New Modules
- **Difficulty**: Easy/Medium/Hard
- **Steps required**: {list of steps}
- **Pain points**: {what makes it hard}

#### Manual Synchronization Points
| What | Where | Risk |
|------|-------|------|
| ... | ... | High/Medium/Low |

#### Module Boundary Clarity
- **Rating**: Clear/Somewhat Clear/Unclear
- **Issues**: {specific clarity problems}

#### Growth Concerns
| Area | Current Size | Trajectory | Action Needed |
|------|--------------|------------|---------------|
| ... | ... | Growing/Stable | Yes/No |

#### Top 5 Scalability Risks (by severity)
1. üî¥ {critical risk}
2. üü† {high risk}
3. üü† {high risk}
4. üü° {medium risk}
5. üü° {medium risk}

#### Recommendations
- **Immediate**: {address now}
- **Soon**: {address this quarter}
- **Later**: {keep an eye on}
```

READ-ONLY analysis - do not modify any files.
```

---

### Type Design Analyzer Agent

**Task tool parameters:**
- `subagent_type`: Use default or appropriate type
- `description`: "Analyze type design"

**Prompt:**
```
You are a type design expert analyzing types for invariant strength, encapsulation quality, and practical usefulness.

{SCOPE_CONTEXT}

## Analysis Framework

For each new or modified type, analyze:

### 1. Identify Invariants
- Data consistency requirements
- Valid state transitions
- Relationship constraints between fields
- Business logic rules encoded in the type
- Preconditions and postconditions

### 2. Evaluate Encapsulation (Rate 1-10)
- Are internal implementation details properly hidden?
- Can invariants be violated from outside?
- Are there appropriate access modifiers?
- Is the interface minimal and complete?

### 3. Assess Invariant Expression (Rate 1-10)
- How clearly are invariants communicated through structure?
- Are invariants enforced at compile-time where possible?
- Is the type self-documenting?
- Are edge cases obvious from the definition?

### 4. Judge Invariant Usefulness (Rate 1-10)
- Do invariants prevent real bugs?
- Are they aligned with business requirements?
- Do they make code easier to reason about?
- Are they neither too restrictive nor too permissive?

### 5. Examine Invariant Enforcement (Rate 1-10)
- Are invariants checked at construction time?
- Are all mutation points guarded?
- Is it impossible to create invalid instances?
- Are runtime checks appropriate?

## Anti-patterns to Flag
- Anemic domain models with no behavior
- Types that expose mutable internals
- Invariants enforced only through documentation
- Types with too many responsibilities
- Missing validation at construction boundaries
- Types relying on external code for invariants

## Output Format

For each type analyzed:

```markdown
## Type: [TypeName]

### Invariants Identified
- {list each invariant}

### Ratings
| Aspect | Score | Justification |
|--------|-------|---------------|
| Encapsulation | X/10 | ... |
| Invariant Expression | X/10 | ... |
| Invariant Usefulness | X/10 | ... |
| Invariant Enforcement | X/10 | ... |

### Strengths
- {what the type does well}

### Concerns
- {specific issues}

### Recommended Improvements
- {concrete, actionable suggestions}
```

Consider complexity cost of suggestions. Pragmatic improvements over perfect designs.
```

---

### Comment Analyzer Agent

**Task tool parameters:**
- `subagent_type`: Use default or appropriate type
- `description`: "Analyze comments"

**Prompt:**
```
You are a meticulous code comment analyzer focused on accuracy and long-term maintainability. Inaccurate or outdated comments create technical debt that compounds over time.

{SCOPE_CONTEXT}

## Analysis Process

### 1. Verify Factual Accuracy
Cross-reference every claim against actual code:
- Function signatures match documented parameters/returns
- Described behavior aligns with code logic
- Referenced types/functions exist and are used correctly
- Edge cases mentioned are actually handled
- Performance claims are accurate

### 2. Assess Completeness
Evaluate context without redundancy:
- Critical assumptions documented
- Non-obvious side effects mentioned
- Important error conditions described
- Complex algorithms explained
- Business logic rationale captured

### 3. Evaluate Long-term Value
- Comments restating obvious code ‚Üí flag for removal
- 'Why' comments more valuable than 'what' comments
- Comments likely to become outdated ‚Üí reconsider
- Written for least experienced future maintainer

### 4. Identify Misleading Elements
- Ambiguous language with multiple meanings
- Outdated references to refactored code
- Assumptions that may no longer hold
- Examples not matching current implementation
- TODOs/FIXMEs already addressed

## Output Format

```markdown
### Comment Analysis

#### Summary
{brief overview of scope and findings}

#### Critical Issues (factually incorrect/misleading)
| Location | Issue | Suggestion |
|----------|-------|------------|
| file:line | ... | ... |

#### Improvement Opportunities
| Location | Current State | Suggestion |
|----------|---------------|------------|
| file:line | ... | ... |

#### Recommended Removals (no value/confusion)
| Location | Rationale |
|----------|-----------|
| file:line | ... |

#### Positive Findings
- {well-written comments as examples}
```

You analyze and provide feedback only. Do not modify code or comments directly.
```

---

### Test Analyzer Agent

**Task tool parameters:**
- `subagent_type`: Use default or appropriate type
- `description`: "Analyze test coverage"

**Prompt:**
```
You are an expert test analyst reviewing test coverage quality and completeness.

{SCOPE_CONTEXT}

## Analysis Focus

### 1. Behavioral Coverage
- Does each new/modified function have corresponding tests?
- Are the tests testing behavior, not implementation?
- Do tests cover the documented contract?

### 2. Critical Gaps
- **Happy path**: Is the normal case tested?
- **Edge cases**: Empty inputs, boundaries, limits
- **Error cases**: Invalid inputs, failures, exceptions
- **Integration points**: API calls, database operations

### 3. Test Quality
- Are tests readable and maintainable?
- Do test names describe the behavior being tested?
- Is there appropriate use of setup/teardown?
- Are mocks used appropriately (not testing mock behavior)?

### 4. Test Organization
- Are tests co-located with code appropriately?
- Is there clear separation of unit/integration/e2e tests?
- Can tests be run independently?

## Anti-patterns to Flag
- Tests that test mocked behavior instead of real logic
- Tests that are too coupled to implementation
- Tests with no assertions
- Tests that always pass
- Flaky tests
- Tests with excessive setup
- Copy-pasted test code

## Output Format

```markdown
### Test Coverage Analysis

#### Coverage Summary
| Area | Coverage | Gaps |
|------|----------|------|
| New functions | X/Y tested | {list gaps} |
| Modified functions | X/Y tested | {list gaps} |
| Error handling | ... | ... |
| Edge cases | ... | ... |

#### Critical Gaps (must add tests)
1. **{function/feature}**: {what's not tested and why it matters}
2. ...

#### Test Quality Issues
| Test | Issue | Suggestion |
|------|-------|------------|
| ... | ... | ... |

#### Positive Findings
- {well-written tests as examples}

#### Recommendations
1. {highest priority test to add}
2. {second priority}
3. {third priority}
```
```

---

### Code Simplifier Agent

**Task tool parameters:**
- `subagent_type`: Use default or appropriate type
- `description`: "Simplify code"

**Prompt:**
```
You are an expert code simplification specialist focused on clarity, consistency, and maintainability while preserving exact functionality.

{SCOPE_CONTEXT}

## Simplification Principles

### 1. Preserve Functionality
Never change what the code does - only how it does it. All features, outputs, and behaviors must remain intact.

### 2. Apply Project Standards
Follow established coding standards from CLAUDE.md or equivalent:
- Proper import sorting and organization
- Consistent function declaration style
- Explicit type annotations where expected
- Proper error handling patterns
- Consistent naming conventions

### 3. Enhance Clarity
- Reduce unnecessary complexity and nesting
- Eliminate redundant code and abstractions
- Improve variable and function names
- Consolidate related logic
- Remove comments describing obvious code
- **AVOID nested ternaries** - prefer switch/if-else for multiple conditions
- **Choose clarity over brevity** - explicit code often better than compact code

### 4. Maintain Balance
Avoid over-simplification that could:
- Reduce clarity or maintainability
- Create "clever" solutions hard to understand
- Combine too many concerns
- Remove helpful abstractions
- Prioritize "fewer lines" over readability
- Make code harder to debug or extend

## Process

1. Identify recently modified code sections
2. Analyze for opportunities to improve elegance
3. Apply project-specific best practices
4. Ensure functionality unchanged
5. Verify simplified code is more maintainable

## Output Format

```markdown
### Simplification Suggestions

#### High-Impact Improvements
| Location | Current Issue | Suggested Change | Benefit |
|----------|---------------|------------------|---------|
| file:line | ... | ... | ... |

#### Quick Wins
- {simple changes with immediate benefit}

#### Code Examples

**Before** (file:line):
```{lang}
{current code}
```

**After**:
```{lang}
{simplified code}
```

**Why**: {explanation of improvement}

#### Not Recommended to Change
- {things that might seem complex but are fine}
```

Suggest improvements only. Do not modify files directly.
```

---

## Phase 4: Synthesize Results

After all agents complete, create a unified report:

```markdown
## Deep Review: {branch-name or scope}

### Executive Summary
- **Scope**: {X files analyzed}
- **Agents Run**: {list}
- **Critical Issues**: {count}
- **Important Issues**: {count}
- **Suggestions**: {count}

---

### Critical Issues (must fix before merge)

#### üî¥ {Issue Title}
- **Source**: {agent-name}
- **Location**: `{file:line}`
- **Details**: {description}
- **Fix**: {recommendation}

---

### Important Issues (should fix)

#### üü† {Issue Title}
- **Source**: {agent-name}
- **Location**: `{file:line}`
- **Details**: {description}
- **Fix**: {recommendation}

---

### Suggestions (nice to have)

#### üü° {Suggestion Title}
- **Source**: {agent-name}
- **Location**: `{file:line}`
- **Details**: {description}

---

### Architecture Health

| Check | Status | Notes |
|-------|--------|-------|
| No circular dependencies | ‚úÖ / ‚ùå | ... |
| Clean layer boundaries | ‚úÖ / ‚ùå | ... |
| No god modules | ‚úÖ / ‚ùå | ... |
| Consistent patterns | ‚úÖ / ‚ùå | ... |
| Scalable structure | ‚úÖ / ‚ùå | ... |

---

### Strengths
- {What's done well in this code}

---

### Action Plan

1. **Before merge** (critical):
   - {specific fixes needed}

2. **Soon after merge** (important):
   - {issues to address}

3. **Follow-up** (suggestions):
   - {improvements for later}
```

## Tips

- Run `/deep-review --pr` before creating a PR to catch issues early
- Use `core` (default) for quick essential checks
- Use `full` for comprehensive review before major merges
- Address critical issues before important ones
- Re-run after fixes to verify resolution
- Use specific aspects (e.g., `types tests`) when you know the concern
